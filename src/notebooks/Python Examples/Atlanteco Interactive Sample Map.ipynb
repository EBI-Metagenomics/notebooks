{
 "cells": [
  {
   "cell_type": "raw",
   "id": "003ddb34-a276-4b23-8888-9f514272b7b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Interactive map for AtlantECO project\"\n",
    "author: \"Kate S [Ekaterina Sakharova] (MGnify team)\"\n",
    "categories: [Python]\n",
    "execute: \n",
    "  enabled: false\n",
    "  eval: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ee428-a8a6-42a8-b2d8-f7df41987a78",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1200px\"><img src=\"../_resources/mgnify_banner.png\" width=\"100%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de3e3b-c12a-4472-8ffe-710494e44bd1",
   "metadata": {},
   "source": [
    "<img src=\"../_resources/mgnify_logo.png\" width=\"200px\">\n",
    "\n",
    "# Mapping samples from the [AtlantECO Super Study](https://www.ebi.ac.uk/metagenomics/super-studies/atlanteco)\n",
    "### ... using the MGnify API and an interactive map widget\n",
    "\n",
    "The [MGnify API](https://www.ebi.ac.uk/metagenomics/api/v1) returns JSON data. The `jsonapi_client` package can help you load this data into Python, e.g. into a Pandas dataframe.\n",
    "\n",
    "**This example shows you how to load a MGnify Super Study's data from the MGnify API and display it on an interactive world map**\n",
    "\n",
    "You can find all of the other \"API endpoints\" using the [Browsable API interface in your web browser](https://www.ebi.ac.uk/metagenomics/api/v1). The URL you see in the browsable API is exactly the same as the one you can use in this code.\n",
    "\n",
    "This is an interactive code notebook (a Jupyter Notebook).\n",
    "To run this code, click into each cell and press the â–¶ button in the top toolbar, or press `shift+enter`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6dd3f-2ff7-4d27-947c-54e648b0912b",
   "metadata": {},
   "source": [
    "## Fetch all [AtlantECO](https://www.ebi.ac.uk/metagenomics/super-studies/atlanteco) studies\n",
    "A Super Study is a collection of MGnify Studies originating from a major project. AtlantECO is one such project, aiming to develop and apply a novel, unifying framework that provides knowledge-based resources for a better understanding and management of the Atlantic Ocean and its ecosystem services.\n",
    "\n",
    "Fetch the Super Study's Studies from the MGnify API, into a [Pandas dataframe](https://pandas.pydata.org/docs/user_guide/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78657238-8961-4fe9-ac64-02dda587c8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jsonapi_client import Session, Modifier\n",
    "\n",
    "atlanteco_endpoint = 'super-studies/atlanteco/flagship-studies'\n",
    "with Session(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    studies = map(lambda r: r.json, mgnify.iterate(atlanteco_endpoint))\n",
    "    studies = pd.json_normalize(studies)\n",
    "studies[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae10b66-889b-4932-b62d-37b89feac050",
   "metadata": {},
   "source": [
    "## Show the studies' samples on a map\n",
    "\n",
    "We can fetch the Samples for each Study, and concatenate them all into one Dataframe.\n",
    "Each sample has geolocation data in its `attributes` - this is what we need to build a map.\n",
    "\n",
    "It takes time to fetch data for all samples, so **let's show samples from the first 6 studies only.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d0fc9-5c05-4bb1-b401-507b6e8c8877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "studies_samples = []\n",
    "\n",
    "with Session(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    for idx, study in studies[:6].iterrows():\n",
    "        print(f\"fetching {study.id} samples\")\n",
    "        samples = map(lambda r: r.json, mgnify.iterate(f'studies/{study.id}/samples?page_size=1000'))\n",
    "        samples = pd.json_normalize(samples)\n",
    "        samples = pd.DataFrame(data={\n",
    "            'accession': samples['id'],\n",
    "            'sample_id': samples['id'],\n",
    "            'study': study.id, \n",
    "            'lon': samples['attributes.longitude'],\n",
    "            'lat': samples['attributes.latitude'],\n",
    "            'color': \"#FF0000\",\n",
    "        })\n",
    "        samples.set_index('accession', inplace=True)\n",
    "        studies_samples.append(samples)\n",
    "studies_samples = pd.concat(studies_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f503c45-d3c0-45b8-a9d5-e3d3eb69ce95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"fetched {len(studies_samples)} samples\")\n",
    "\n",
    "studies_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09ddf3-746e-4891-96a5-8f70682d530f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import leafmap\n",
    "m = leafmap.Map(center=(0, 0), zoom=2)\n",
    "m.add_points_from_xy(\n",
    "    studies_samples,\n",
    "    x='lon', \n",
    "    y='lat', \n",
    "    popup=[\"study\", \"sample_id\"], \n",
    "    color_column='color',\n",
    "    add_legend=False\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc7b990-0804-43a3-bfc8-dc14e5a61a88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check GO term presence\n",
    "Let's check whether a specific identifier is present in each sample. This example is written for GO-term 'GO:0015878', but other identifier types are available on the MGnify API.\n",
    "\n",
    "We will work with MGnify analyses (`MGYA`s) corresponding to chosen samples. We filter analyses by \n",
    "- pipeline version: 5.0\n",
    "- experiment type: assembly\n",
    "\n",
    "This example shows how to process **just the first 10 samples** (again, because the full dataset takes a while to fetch).\n",
    "Firstly, get analyses for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d6790-1cec-4ecf-b8be-56e3e03fe669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyses = []\n",
    "with Session(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    for idx, sample in studies_samples[:10].iterrows():\n",
    "        print(f\"processing {sample.sample_id}\")\n",
    "        filtering = Modifier(f\"pipeline_version=5.0&sample_accession={sample.sample_id}&experiment_type=assembly\")\n",
    "        analysis = map(lambda r: r.json, mgnify.iterate('analyses', filter=filtering))\n",
    "        analysis = pd.json_normalize(analysis)\n",
    "        analyses.append(analysis)\n",
    "analyses = pd.concat(analyses)\n",
    "analyses[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ad3aa-f19f-4007-b64f-59edf10b5734",
   "metadata": {},
   "source": [
    "Next, check each analysis for GO term presence/absence. We add a column to the dataframe with a colour: blue if GO term was found and red if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6980125-7fd7-4fdb-9f15-c1b9c93a21c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier = \"go-terms\"\n",
    "go_term = 'GO:0015878'\n",
    "go_data = []\n",
    "with Session(\"https://www.ebi.ac.uk/metagenomics/api/v1\") as mgnify:\n",
    "    for idx, mgya in analyses.iterrows():\n",
    "        print(f\"processing {mgya.id}\")\n",
    "        analysis_identifier = map(lambda r: r.json, mgnify.iterate(f'analyses/{mgya.id}/{identifier}'))\n",
    "        analysis_identifier = pd.json_normalize(analysis_identifier)\n",
    "        go_data.append(\"#0000FF\" if go_term in list(analysis_identifier.id) else \"#FF0000\")\n",
    "analyses.insert(2, identifier, go_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4242af-617a-4ad9-b265-f7b629da9b52",
   "metadata": {},
   "source": [
    "Join the analyses and sample tables to have geolocation data and identifier presence data together.\n",
    "\n",
    "We'll create a new sub-DataFrame with a subset of the fields and add them to the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decacbe-04ed-4fdc-93fe-9f3acd78624b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = analyses.join(studies_samples.set_index('sample_id'), on='relationships.sample.data.id')\n",
    "df2 = df[[identifier, 'lon', 'lat', 'study', 'attributes.accession', 'relationships.study.data.id', 'relationships.sample.data.id', 'relationships.assembly.data.id']].copy()\n",
    "df2 = df2.set_index(\"study\")\n",
    "df2 = df2.rename(columns={\"attributes.accession\": \"analysis_ID\", \n",
    "                          'relationships.study.data.id': \"study_ID\",\n",
    "                          'relationships.sample.data.id': \"sample_ID\", \n",
    "                          'relationships.assembly.data.id': \"assembly_ID\"\n",
    "                         })\n",
    "m = leafmap.Map(center=(0, 0), zoom=2)\n",
    "m.add_points_from_xy(df2, \n",
    "                     x='lon', \n",
    "                     y='lat', \n",
    "                     popup=[\"study_ID\", \"sample_ID\", \"assembly_ID\", \"analysis_ID\"],\n",
    "                    color_column=identifier, add_legend=False)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985abb6-73a6-418f-8657-5fb383022d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mgnify-py-env)",
   "language": "python",
   "name": "conda-env-mgnify-py-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
